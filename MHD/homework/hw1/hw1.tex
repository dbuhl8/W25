\documentclass{article}

\usepackage{graphicx} % Required for inserting images
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{amsmath}
\usepackage{amsthm} %proof environment
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{enumitem} %nice lists
\usepackage{verbatim} %useful for something 
\usepackage{xcolor}
\usepackage{setspace}
\usepackage{titlesec}
\usepackage{blindtext} % I have no idea what this is 
\usepackage{caption}  % need this for unnumbered captions/figures
\usepackage{natbib}
\usepackage{tikz}
\usepackage{hyperref}


\titleformat{\section}{\bfseries\Large}{Problem \thesection:}{5pt}{}
\begin{document}

\doublespacing

\title{AM 275 - Magnetohydrodynamics: Homework 1}
\author{Dante Buhl}


\newcommand{\wrms}{w_{\text{rms}}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\tb}[1]{\textbf{#1}}
\newcommand{\bmp}[1]{\begin{minipage}{#1\textwidth}}
\newcommand{\emp}{\end{minipage}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\K}{\bs{\mathrm{K}}}
\newcommand{\m}{\bs{\mu}_*}
\newcommand{\s}{\bs{\Sigma}_*}
\newcommand{\dt}{\Delta t}
\newcommand{\dx}{\Delta x}
\newcommand{\tr}[1]{\text{Tr}(#1)}
\newcommand{\Tr}[1]{\text{Tr}(#1)}
\newcommand{\Div}{\nabla \cdot}
\renewcommand{\div}{\nabla \cdot}
\newcommand{\Curl}{\nabla \times}
\newcommand{\Grad}{\nabla}
\newcommand{\grad}{\nabla}
\newcommand{\grads}{\nabla_s}
\newcommand{\gradf}{\nabla_f}
\newcommand{\xs}{x_s}
\newcommand{\xf}{x_f}
\newcommand{\ts}{t_s}
\newcommand{\tf}{t_f}
\newcommand{\pt}{\partial t}
\newcommand{\pz}{\partial z}
\newcommand{\uvec}{\bs{u}}
\newcommand{\bvec}{\bs{B}}
\newcommand{\jvec}{\bs{j}}
\newcommand{\F}{\bs{F}}
\newcommand{\B}{\bs{B}}
\newcommand{\E}{\bs{E}}
\newcommand{\T}{\tilde{T}}
\newcommand{\ez}{\bs{e}_z}
\newcommand{\ex}{\bs{e}_x}
\newcommand{\ey}{\bs{e}_y}
\newcommand{\eo}{\bs{e}_{\bs{\Omega}}}
\newcommand{\ppt}[1]{\frac{\partial #1}{\partial t}}
\newcommand{\DDt}[1]{\frac{D #1}{D t}}
\newcommand{\ppts}[1]{\frac{\partial #1}{\partial t_s}}
\newcommand{\pptf}[1]{\frac{\partial #1}{\partial t_f}}
\newcommand{\ppz}[1]{\frac{\partial #1}{\partial z}}
\newcommand{\ddz}[1]{\frac{d #1}{d z}}
\newcommand{\ppzetas}[1]{\frac{\partial^2 #1}{\partial \zeta^2}}
\newcommand{\ppzs}[1]{\frac{\partial #1}{\partial z_s}}
\newcommand{\ppzf}[1]{\frac{\partial #1}{\partial z_f}}
\newcommand{\ppx}[1]{\frac{\partial #1}{\partial x}}
\newcommand{\ppxi}[1]{\frac{\partial #1}{\partial x_i}}
\newcommand{\ppxj}[1]{\frac{\partial #1}{\partial x_j}}
\newcommand{\ppxm}[1]{\frac{\partial #1}{\partial x_m}}
\newcommand{\ppy}[1]{\frac{\partial #1}{\partial y}}
\newcommand{\ppzeta}[1]{\frac{\partial #1}{\partial \zeta}}


\maketitle 
% This line removes the automatic indentation on new paragraphs
\setlength{\parindent}{0pt}

\section{}

Show that 
\begin{gather*}
    u_i\ppxj{\tau_{ij}} = \ppxj{u_i\tau_{ij}} + pe_{kk} -
    2\mu\left[e_{ij} - \frac{1}{3}e_{kk}\delta_{ij}\right]^2. 
\end{gather*}

\begin{proof}
    First, we begin with the derivative identity
    \begin{gather*}
        u_i\ppxj{\tau_{ij}} = \ppxj{u_i\tau_{ij}} - \tau_{ij}\ppxj{u_i}
    \end{gather*}
    and in order to simplify this statement, take $\tau_i$ to be the i-th row
    vector of $\tau$, we have:
    \begin{gather*}
        \sum_i u_i\div{\tau_i} = \sum_i\div{u_i\tau_i} - \tau_i\cdot\grad u_i
    \end{gather*}
    Already we have shown the first RHS term originates from the derivative
    identity, whereas the other terms must originate from
    $-\sum_i\tau_i\cdot\grad u_i$. Thus, we investigate this term in more
    detail. 
    \begin{gather*}
        -\sum_i\tau_i\cdot\grad u_i =\sum_i \left[p +
        \frac{2}{3}\mu\grad\cdot\uvec\right]\delta_{ij}\cdot\grad u_i - 2\mu
        e_i\cdot\grad u_i
    \end{gather*}
    where $e_{kk}$ is written as $\grad\cdot\uvec$ and $e_i$ is the i-th row of
    $e$ (as in $e_{ij}$). Notice that $\sum_{i}\delta_{ij}\cdot\grad u_i =
    \grad\cdot\uvec$, and therefore, 
    \begin{align*}
         -\sum_i\tau_i\cdot\grad u_i &= \left[p +
        \frac{2}{3}\mu\grad\cdot\uvec\right](\grad\cdot\uvec) - 2\mu
        \sum_ie_i\cdot\grad u_i\\
        &= p(\div{\uvec}) + \frac{2}{3}\mu(\div{\uvec})^2 - 2\mu
        \sum_ie_i\cdot\grad u_i
    \end{align*}
    Thus we recover the second RHS term, $pe_{kk}$. Now we must show the rest of
    $-\sum_i\tau_i\cdot\grad u_i$ recovers the last term of the RHS. We write
    the decomposition of $e_{i}$. 
    \begin{align*}
        -2\mu\sum_ie_i\cdot\grad u_i &= -\mu\sum_i \left(\grad u_i +
        \ppxi{\uvec}\right)\cdot\grad u_i\\
        &= -\mu \sum_i |\grad u_i|^2 + \ppxi{\uvec}\cdot\grad u_i\\
        &= -\mu |\grad\uvec|^2 - \mu\sum_i \ppxi{\uvec}\cdot\grad u_i\\
        &= -\mu |\grad\uvec|^2 - \mu\ppxj{u_i}\cdot\ppxi{u_j}
        %\left((\grad\cdot\uvec)^2 + 2\left(\ppx{v}\ppy{u}
        %+ \ppx{w}\ppz{u} + \ppy{w}\ppz{v}\right)\right)
    \end{align*}
    Now we must show by the transitive propery that,
    \begin{align*}
        \frac{2}{3}\mu(\div{\uvec})^2 - \mu |\grad\uvec|^2 -
        \mu\sum_{ij}\ppxj{u_i}\ppxi{u_j} &= -
        2\mu\left[e_{ij} - \frac{1}{3}e_{kk}\delta_{ij}\right]^2_{ll}
    \end{align*}
    We begin by writing the inner product of these second order tensors and then
    taking the contraction (necessary in order to obtain a scalar) (also sorry
    about the indices, I couldn't decide which letters I wanted to stick with in
    the long run)
    \begin{align*}
        -2\mu\left[e_{ij} -
        \frac{1}{3}e_{kk}\delta_{ij}\right]^2_{ll}&=
        -2\mu\left[(e_{ij}^2)_{ll}
        - \frac{2}{3}(\div{\uvec})e_{ll} +
        \frac{1}{9}(\div{\uvec})^2\delta_{ll}\right]\\
        &=-2\mu\left[(e_{im}\cdot e_{mj})_{ll}
        -\frac{2}{3}(\div{\uvec})^2 + \frac{1}{3}(\div{\uvec}^2)\right]\\
        &= -\frac{\mu}{2}\left(\ppxm{u_i}\ppxj{u_m} + \ppxi{u_m}\ppxj{u_m} +
        \ppxm{u_i}\ppxm{u_j} + \ppxi{u_m}\ppxm{u_j}\right)_{ll} +
        \frac{2}{3}\mu(\div{\uvec})^2\\
        &=-\frac{\mu}{2}\left(\grad u_i\cdot \ppxi{\uvec} +
        \ppxi{\uvec}\cdot\ppxi{\uvec} + \grad u_i\cdot\grad u_i +
        \ppxi{\uvec}\cdot\grad u_i\right) + \frac{2}{3}\mu(\div{\uvec})^2\\
        &=-\frac{\mu}{2}\left(2|\grad\uvec|^2 +
        2\ppxj{u_i}\ppxi{u_j}\right) + \frac{2}{3}\mu(\div{\uvec})^2\\
        &= \frac{2}{3}\mu(\div{\uvec})^2  -\mu|\grad\uvec|^2 - \mu\ppxj{u_i}\ppxi{u_j}
    \end{align*}
    Therefore, we have shown that 
    \begin{align*}
        u_i\ppxj{\tau_{ij}} &= \ppxj{u_i\tau_{ij}} + p(\div{\uvec}) +
        \frac{2}{3}\mu(\div{\uvec})^2 - \mu|\grad\uvec|^2 -
        \mu\ppxj{u_i}\ppxi{u_j}\\
        &= \ppxj{u_i\tau_{ij}} + pe_{kk} - 2\mu\left[e_{ij} -
        \frac{1}{3}e_{kk}\delta_{ij}\right]^2
    \end{align*}
    where $[\cdot]^2$ implies a tensor ``double dot product'', where first a
    (tensor) inner
    product is taken and the resultant
    second order tensor is contracted to become a scalar. 
\end{proof}

\section{}

\subsection{Show that the imcompressible induction equation is}
\begin{gather*}
    \ppt{\B} + (\uvec\cdot\grad)\B = (\B\cdot\grad)\uvec
\end{gather*}

\begin{proof}
    We begin by writing the (non-diffusive) induction equation and the corresponding derivative
    identity. 
    \begin{gather*}
        \ppt{\B} = \grad\times(\uvec\times\B)\\
        \grad\times(\uvec\times\B) = \uvec(\div{\B})-\B(\div{\uvec}) +
        (\B\cdot\grad)\uvec - (\uvec\cdot\grad)\B
    \end{gather*}
    Using this substitution and keeping in mind that $\div{\B} = 0$ and
    $\div{\uvec} = 0$ we obtain, 
    \begin{gather*}
        \ppt{\B} + (\uvec\cdot\grad)\B = (\B\cdot\grad)\uvec
    \end{gather*}
\end{proof}

\subsection{Show that the compressible induction equation can be written as}
\begin{gather*}
    \ppt{}\left(\frac{\B}{\rho}\right) +
    (\uvec\cdot\grad)\left(\frac{\B}{\rho}\right) =
    \left(\frac{\B}{\rho}\cdot\grad\right)\uvec
\end{gather*}

\begin{proof}
    We begin by taking the compressible induction equation and multiplying by
    $1/\rho$. 
    \begin{gather*}
        \frac{1}{\rho}\ppt{\B} + \frac{1}{\rho}(\uvec\cdot\grad)\B =
        \frac{1}{\rho}(\B\cdot\grad)\uvec - \frac{1}{\rho}\B(\div{\uvec})
    \end{gather*}
    Then, we use the product rule derivative identity to change some of the
    derivatives. We have,
    \begin{gather*}
        \ppt{}\left(\frac{\B}{\rho}\right) + \frac{\B}{\rho^2}\ppt{\rho} + 
        (\uvec\cdot\grad)\frac{\B}{\rho} + 
        \frac{\B}{\rho^2}(\uvec\cdot\grad)\rho =
        \left(\frac{\B}{\rho}\cdot\grad\right)\uvec -
        \frac{\B}{\rho}(\div{\uvec})
    \end{gather*}
    Here we consider the conservation of mass equation which for compressible
    fluids is written as,
    \begin{gather*}
        \ppt{\rho} + \div{\rho\uvec} = 0\\
        \frac{1}{\rho^2}\ppt{\rho} + \frac{1}{\rho^2}(\div{\rho\uvec}) = 0\\
        \frac{1}{\rho^2}\ppt{\rho} + \frac{1}{\rho^2}\left(\rho(\div{\uvec}) +
        (\uvec\cdot\grad)\rho\right) = 0\\
        \frac{1}{\rho^2}\ppt{\rho} + \frac{1}{\rho^2}
        (\uvec\cdot\grad)\rho = -\frac{1}{\rho}(\div{\uvec}).
    \end{gather*}
    BNotice that we can take this equation, multiply it by $\B$ and subtract it
    from the induction equation. This leaves us with, 
    \begin{gather*}
        \ppt{}\left(\frac{\B}{\rho}\right) + 
        (\uvec\cdot\grad)\frac{\B}{\rho} =
        \left(\frac{\B}{\rho}\cdot\grad\right)\uvec
    \end{gather*}

\end{proof}

\section{}
\subsection{Derive the induction equation given that $\sigma$ is not necessarily
constant}
\begin{proof}
    Let us begin with Ohm's law as we have written in lecture. 
    \begin{gather*}
        \jvec = \jvec' = \sigma\E'\\
        \E' = \E + \uvec\times\B\\
        \grad\times\B = \mu_0\sigma(\E + \uvec\times\B)\\
        \grad\times\left(\frac{1}{\mu_0\sigma}\grad\times\B\right) =
        \grad\times\E + \grad\times(\uvec\times\B)\\
        \frac{1}{\mu_0\sigma}(\grad\times\grad\times\B) - 
        \frac{1}{\mu_0\sigma^2}\grad\sigma\times\left(\grad\times\B\right) = 
        -\ppt{\B} + \grad\times(\uvec\times\B)\\
        \ppt{\B} = 
        \frac{1}{\mu_0\sigma}\grad^2\B + 
        \frac{1}{\mu_0\sigma^2}((\grad\B)^T\cdot\grad\sigma -
        (\grad\sigma\cdot\grad)\B)
         + \grad\times(\uvec\times\B)
    \end{gather*}
    This can then be simplified keeping in mind that $\div{\B} = 0$, and
    especially if the flow is incompresible, to the following:
    \begin{gather*}
        \ppt{\B} + (\uvec\cdot\grad)\B +
        \frac{1}{\mu_0\sigma^2}(\grad\sigma\cdot\grad)\B = 
        (\B\cdot\grad)\uvec + 
        \frac{1}{\mu_0\sigma^2}((\grad\B)^T\cdot\grad\sigma) + 
        \frac{1}{\mu_0\sigma}\grad^2\B 
    \end{gather*}
    Essentially we see the appearence of two new terms if the conductivity is
    not constant. First, the advection of
    $\B$ by the gradient of conductivity, and then some weird term related to
    $\grad\B^T$ on the RHS. 
\end{proof}

\section{}

\subsection{Show that initial conditions of the divergence of the magnetic field are preserved for Maxwell's equations}
\begin{proof}
    In order to show this, we must first assume that the temporal and spatial
    derivatives can be taken in any order, i.e. $\ppt{}\left(\ppx{u}\right) =
    \ppx{}\left(\ppt{u}\right)$. 
    We proceed by taking the dot product of Faraday's law, 
    \begin{gather*}
        \grad\cdot\ppt{\B} = \grad\cdot(-\grad\times\E)\\
        \ppt{}(\grad\cdot\B) = 0
    \end{gather*}
    where the RHS is zero because the divergence of a curl is always zero. Thus
    if we have that $\div{\B} = 0$ at $t = 0$, it will always be zero. 
\end{proof}

\subsection{Show that initial conditions of the divergence of the magnetic field are preserved for the induction equation}

\begin{proof}
    A similar proof can be written from the perspective of the induction
    equation. Let us write a form of the induction equation, 
    \begin{gather*}
        \ppt{\B} = - \grad\times\left(\frac{1}{\mu_0\sigma}\grad\times\B\right) + \grad\times(\uvec\times\B)
    \end{gather*}
    where $\sigma$ is not necessarily a constant and the fluid is not
    necessarily incompressible. Similarly, we take the divergence of this
    equation and obtain,
    \begin{gather*}
        \ppt{}(\div{\B})  = \grad\cdot\left(
        \grad\times\left(\frac{1}{\mu_0\sigma}\grad\times\B\right) +
        \grad\times(\uvec\times\B)\right)\\
        \ppt{}(\div{\B})  = 0
    \end{gather*}
    since again, the divergence of a curl is always zero. Therefore, from the
    perspective of the induction equation, we have that $\div{\B} = 0$ will be
    maintained for all $t>0$ if $\div{\B} = 0$ at $t=0$. 
\end{proof}



\end{document}
